---
title: "Intermediate `climr` workflow"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 2
description: >
  More advanced `climr` workflows.
vignette: >
  %\VignetteIndexEntry{Intermediate `climr` workflow}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
bibliography: references.bib
link-citations: true
code_folding: show
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = FALSE,
  warning = FALSE,
  fig.dim = c(7, 5),
  fig.align = "center"
)

if (!require(ggplot2)) {
  warning("'ggplot2' is not installed. Some visuals won't be available.")
}

cpath <- if (interactive()) {
  normalizePath("climr.cache", winslash = "/")
} else {
  normalizePath(file.path(tempdir(), "climr.cache"), winslash = "/")
}
options("climr.cache.path" = cpath)
```

## Introduction

`climr` is in essence similar to [ClimateNA](climatena.ca) in that it
downscales low-resolution (\~100km) global climate model anomalies to
high-resolution (1-4km) maps of climate, with further elevation
adjustment to user-specified elevation grids/points based on empirical
lapse rates (local relationship of climate to elevation) of the 1-4km
climate maps. The elevation-adjusted monthly values of basic climate
elements (temperature and precipitation) are then used to estimate
derived variables (e.g., degree-days, precipitation as snow) based on
published equations and parameters from [@wang2016].

See `vignette("methods_downscaling.Rmd")` for a detailed explanation of
the downscaling methodology employed in `climr`.

`climr`'s strenghts are:

1.  its ability to obtain multiple, individual runs of a (or several)
    General Circulation Model(s) (GCM), as well as the ensemble
    cross-run mean,

<!-- benchmark Speed and add it here -->

2.  cloud-based raw data access and local data caching,

3.  and direct `R` interface to downscaled climate elements and derived
    variables covering western Canada and western US.

In this vignette we cover two basic `climr` workflows to obtain historic
and future climate projections of a few derived variables.

The first, less code-heavy, workflow uses `downscale()` to do much
of the heavy lifting -- [Workflow with downscale]. The second
workflow is a step-by-step breakdown of `downscale()` using the
functions `downscale()` calls internally -- [Workflow with
\*\_input functions and downscale].

## Main functions

Below is a list of the main functions used in the two workflows.

-   `downscale()` takes a `data.table` of point coordinates (in
    lat-long projection), obtains climate normals and historic and/or
    future projections covering the extent of the points, which are then
    downscaled using point elevation data and used to calculate derived
    climate variables at the point locations. It outputs the downscaled
    and derived variables in the form of a `data.table` or `SpatVector`
    of points.

-   `input_refmap()` downloads and prepares high-resolution climate
    normals. Called internally by `downscale()`.

-   `input_obs()` and `input_obs_ts()` download and prepare
    low-resolution historic climate elements for a given historic period
    or time series, respectively. Called internally by
    `downscale()`.

-   `input_gcms()`, `input_gcm_hist()` and `input_gcm_ssp()` download and
    prepare low-resolution climate element projections for a future
    period, historic period or future time series, respectively. Called
    internally by `downscale()`.

-   `downscale()` downscales historic or future climate elements and
    calculates derived climate variables. Called by `downscale()`.

## Workflow with `downscale`

In this example workflow we use `downscale()` to calculate mean
annual temperature (MAT), total annual precipitation (PPT) and
precipitation as snow (PAS) at weather stations associated with the
[Adjusted and homogenized Canadian climate
data](https://www.canada.ca/en/environment-climate-change/services/climate-change/science-research-data/climate-trends-variability/adjusted-homogenized-canadian-data.html).

We will downscale MAT, PPT and MAS at these locations for a historic and
a future period, using two separate runs of a GCM and one emissions
scenario.

We begin by loading the Adjusted Precipitation for Canada (APC2) dataset
and clipping it to the North Vancouver area. This dataset already
contains elevation information.

Note that longitude ('lon') and latitude ('lat') must be in lat-long
projection (EPSG:4326) and elevation in m. Point IDs must be unique --
we will use the weather station IDs.

We will also add two other columns in our `data.table` ('ZONE' and
'HEZ') these are ignored by `downscale()`. `downscale()`
preserves the IDs and we use them to join back the extra columns used
for plotting later on.

```{r}
library(climr)
library(data.table)
library(terra)

## weather station locations
weather_stations <- get(data("weather_stations")) |>
  unwrap()

## study area of interest (North Vancouver)
vancouver_poly <- get(data("vancouver_poly")) |>
  unwrap()

## subset to points in study area
weather_stations <- mask(weather_stations, vancouver_poly)

## convert to data.table and subset/rename columns needed by climr
xyzDT <- as.data.table(weather_stations, geom = "XY")
cols <- c("Station ID", "x", "y", "Elevation (m)")
xyzDT <- xyzDT[, ..cols]
setnames(xyzDT, c("id", "lon", "lat", "elev"))

## join BEC zones and colours
BECz_vancouver <- get(data("BECz_vancouver")) |>
  unwrap()

BECz_points <- extract(BECz_vancouver, weather_stations) |>
  as.data.table()
BECz_points <- BECz_points[, .(ZONE, HEX)]

xyzDT <- cbind(xyzDT, BECz_points)

## remove duplicates
xyzDT <- unique(xyzDT)

## there are some duplicate stations with slightly different
## coordinates. We'll take the first
xyzDT <- xyzDT[!duplicated(id)]
```

```{r, echo = FALSE, fig.show = "hold", fig.cap = "Weather stations in North Vancouver", fig.dim = c(7,5), out.width="70%"}
cols <- xyzDT$HEX
names(cols) <- xyzDT$ZONE
cols <- cols[order(names(cols))]
cols <- cols[!duplicated(cols)]
plot(vancouver_poly, col = hcl.colors(50, palette = "Earth"))
plot(vect(xyzDT, geom = c("lon", "lat")),
  y = "ZONE",
  col = cols, plg = list(title = "BEC zone"), add = TRUE
)
```


The `list_*()` functions below provide a list of available historic and
future periods, GCMs, emissions scenarios, and derived variables (in
this case only the annual ones).

```{r}
list_obs_periods()
```

```{r}
list_gcm_periods()
```

```{r}
list_gcms()
```

```{r}
list_ssps()
```

```{r}
list_vars(set = "Annual")
```

We will chose the only available historic period (2001-2020), the
2021-2040 future period, the 'EC-Earth3' GCM and the SSP 2.45 scenario.
MAT, PPT and PAS will be selected as output variables.

We pass our choices to `downscale()`, choosing the climr composite reference climatology (`refmap_climr`).

```{r, message = TRUE}
ds_out <- downscale(
  xyz = xyzDT,
  which_refmap = "refmap_climr",
  obs_periods = "2001_2020",
  gcm_periods = "2021_2040",
  gcms = "EC-Earth3",
  ssps = "ssp245",
  max_run = 2,
  return_refperiod = TRUE, ## to return the 1961-1990 normals period
  vars = c("MAT", "PPT", "PAS")
)
```

Note how data from historical periods doesn't have a GCM or SSP value --
this is expected , as GCMs and SSPs are used to project future climate
values. Also, future projections were obtained for two runs of EC-Earth3
('r1i1p1f1' and 'r10i1p1f1'), plus the ensemble mean.

```{r, echo = FALSE, results = "asis"}
knitr::kable(ds_out[id == head(id, 1)], caption = "'ds_out' table - Output from `downscale`. Outputs are show for one location ('id')")
```

To add back the extra columns we need only a simple left join.

```{r}
ds_out <- xyzDT[, .(id, ZONE, HEX)][ds_out, on = .(id)]
```

We can now do a simple visualisation of climate variation by
biogeoclimatic zone ('ZONE'), in the normals period of 1961-1990:

```{r, echo = TRUE, class.source = 'fold-hide', out.width = "80%", fig.dim = c(8,5), eval = require(ggplot2)}
plotdata <- melt(ds_out, measure.vars = c("MAT", "PPT", "PAS"))
cols <- plotdata$HEX
names(cols) <- plotdata$ZONE
cols <- cols[!duplicated(cols)]

ggplot(plotdata[PERIOD == "1961_1990"], aes(x = ZONE, y = value, fill = ZONE)) +
  geom_boxplot() +
  theme_light() +
  scale_fill_manual(values = cols) +
  facet_wrap(~variable, scales = "free")
```

We may also want yearly climate projections. In this case, we want the
yearly values of MAT and PPT for 2001-2015 and 2021:2040, using the same
GCM, SSP and number of model runs. Notice how some of the data doesn't
need to be downloaded again, and was retrieved from cache.

The `downscale()` internally rescales the projected historical
values so that they align with their observed counterpart. See
`vignette("methods_downscaling.Rmd")` for details.

<!-- missing data for years 2016-2020 -->

```{r, message = TRUE}
ds_out_ts <- downscale(
  xyz = xyzDT,
  obs_years = 2001:2015,
  gcm_hist_years = 2001:2014,
  gcm_ssp_years = 2015:2040,
  gcms = "EC-Earth3",
  ssps = "ssp245",
  max_run = 1,
  return_refperiod = TRUE, ## to return the 1961-1990 normals period
  vars = c("MAT", "PPT", "PAS")
)
```

To plot the time series, we will filter the data to a single model run
(i.e. in this case discard the ensemble means) and to a single point
location. Note that we plot both the observed (`obs_hist`) and the
projected historical (`proj_hist`) climate values along with future
climate projections (`proj_fut`).

```{r, echo = TRUE, class.source = 'fold-hide', fig.cap = "Time series outputs from `downscale`. Pannels show mean annual temperature (MAT), total annual precipitation (PPT) and precipitation as snow (PAS). Line colours refer to observed historic values (grey), projected historic values (gren) and future projected values (blue) for a single location, GCM, emissions scenario and model run.", out.width = "80%", eval = require(ggplot2), fig.dim = c(7,8)}
ds_out_ts[is.na(GCM), GCM := "Historic"]
ds_out_ts <- ds_out_ts[!grepl("ensemble", RUN)]
ds_out_ts <- ds_out_ts[!grepl("1961_1990", PERIOD)]

plotdata <- melt(ds_out_ts, measure.vars = c("MAT", "PPT", "PAS"))
plotdata[, PERIOD := as.numeric(PERIOD)]
plotdata <- plotdata[id == head(id, 1)]

## time series period groupings
plotdata[GCM == "Historic", pgrp := "obs_hist"]
plotdata[GCM != "Historic" & PERIOD <= 2020, pgrp := "proj_hist"]
plotdata[GCM != "Historic" & PERIOD > 2020, pgrp := "proj_fut"]

## make groups so that missing data is not shown as a "line connection"
groups <- data.table(PERIOD = unique(plotdata$PERIOD))
groups[, idx := c(1, diff(PERIOD))]
i2 <- c(1, which(groups$idx != 1), nrow(groups) + 1)
groups[, grp := rep(1:length(diff(i2)), diff(i2))]
plotdata <- groups[, .(PERIOD, grp)][plotdata, on = "PERIOD"]
plotdata[, grp := paste(grp, variable, sep = "_")]

yrbreaks <- c(
  min(plotdata$PERIOD),
  seq(min(plotdata$PERIOD), max(plotdata$PERIOD), by = 5),
  max(plotdata$PERIOD)
) |>
  unique()

ggplot(plotdata, aes(x = PERIOD, y = value, col = pgrp, group = grp)) +
  geom_line(
    data = plotdata[pgrp == "obs_hist"], size = 1.1,
    linejoin = "round", lineend = "round"
  ) +
  geom_line(
    data = plotdata[pgrp != "obs_hist"], size = 1.1,
    linejoin = "round", lineend = "round"
  ) +
  scale_x_continuous(breaks = yrbreaks, labels = yrbreaks) +
  scale_color_manual(
    values = c(
      "obs_hist" = "grey",
      "proj_hist" = "forestgreen",
      "proj_fut" = "navyblue"
    ),
    breaks = c("obs_hist", "proj_hist", "proj_fut")
  ) +
  theme_light() +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5)) +
  labs(x = "Year", col = "") +
  facet_wrap(~variable, scales = "free", ncol = 1, strip.position = "left", )
```

### Spatial output and plotting options

`downscale` can also provide outputs in the form of a `SpatVector`
of points and plot the values of a chosen climate variable from the list
passed to `downscale(..., vars)`, in this case MAT.

```{r, fig.dim = c(8, 6), out.width = "80%"}
ds_out_spatial <- downscale(
  xyz = xyzDT,
  gcms = "EC-Earth3",
  gcm_periods = "2021_2040",
  ssps = "ssp245",
  max_run = 0,
  return_refperiod = FALSE, ## don't return the 1961-1990 normals period
  out_spatial = TRUE,
  plot = "MAT",
  vars = c("MAT", "PPT", "PAS")
)
```

And of course we can now use the vector output to map all variables on
top of our DEM raster, for prettier visuals:

```{r, fig.show = 'hold', fig.dim = c(10, 5), out.width = "100%"}
vancouver <- get(data("vancouver")) |>
  unwrap()

par(mfrow = c(1, 2))
plot(vancouver_poly,
  col = hcl.colors(50, palette = "Earth"),
  plg = list(x = "bottom", title = "Elevation"),
  mar = c(4, 1, 1, 4)
)
plot(vancouver, add = TRUE, col = "black")
plot(ds_out_spatial, "MAT",
  col = hcl.colors(50, palette = "Reds"),
  add = TRUE, type = "continuous",
  plg = list(x = "right", title = "MAT")
)

plot(vancouver_poly,
  col = hcl.colors(50, palette = "Earth"),
  plg = list(x = "bottom", title = "Elevation"),
  mar = c(4, 1, 1, 4)
)
plot(vancouver, add = TRUE, col = "black")
plot(ds_out_spatial, "PPT",
  col = hcl.colors(50, palette = "Blues"),
  add = TRUE, type = "continuous",
  plg = list(x = "right", title = "PPT")
)
```

```{r, include = FALSE}
par(mfrow = c(1, 1))
```

## Workflow with `input_*` functions and `downscale_core()`

Alternatively, a user may choose to run the climate data preparation and
downscaling functions separately.

We suggest doing this at least once or twice to have a full
understanding of the steps that `downscale` executes internally.

Steps 1 and 2 bellow download and prepare the climate data used in the
downscaling step (Step 3).

We will use the same point locations as above for downscaling.

### 1) Get climate normals - `input_refmap()`

When using `input_refmap()`, we establish a connection to the PostGIS
server and pass the bounding box containing the point locations of
interest.

There is no "auto" option to select the source of climate normals.
`list_refmap()` provides a list of available options:

-   'refmap_climatena' corresponds to normals for North America obtained from
[ClimateNA](climatena.ca) [@wang2016];

-   'refmap_climr' corresponds to a composite of British Columbia
    PRISM, adjusted US PRISM and DAYMET (Alberta and Saskatchewan).

We will use 'refmap_climr' has it is the highest resolution product
for the area of interest.


```{r}
list_refmaps()
```

The extent of the downloaded climate anomalies will often be larger
than the extent of the bounding box, and vary depending on the spatial 
resolution of the data. To demonstrate this we will define a bounding 
box with a set of coordinates.

Alternatively, `get_bb` could be used to extract bounding box around the
point locations in `xyzDT`. 

```{r}
dbCon <- data_con()
the_bb <- c(50, 49, -122, -124)

## alternatively:
# the_bb <- get_bb(xyzDT)

normals <- input_refmap(dbCon,
  bbox = the_bb,
  reference = "refmap_climr"
)
```

```{r, echo = FALSE, out.width = "80%", fig.cap = "Downloaded normals shown with North Vancouver area and the requested bounding box."}
plotVect <- vect(ext(the_bb[c(4, 3, 2, 1)]), crs = "EPSG:4326")

plot(normals[["Tmax_07"]],
  col = hcl.colors(50, "Reds", rev = 1),
  range = c(0, 30), main = "Max temp. July - 1961-1990 normals",
  fun = function() {
    polys(vancouver_poly)
    polys(plotVect, lty = 2)
  }
)
```

### 2) Get climate projections and/or historical observations

Data for historic and future climate projections can be obtained with
the `gcm_*()` functions. `input_gcm_hist()` is used to obtain historical
anomalies projected with a (or several) GCM, whereas `input_gcms()` and
`input_gcm_ssp` are used to obtain future anomaly projections for a
period or individual years (i.e. time series).

Historical observations for a given period or for individual years can
be obtained with `input_obs` and `input_obs_ts`, respectively.

```{r}
hist_proj <- input_gcm_hist(dbCon,
  bbox = the_bb,
  gcms = "EC-Earth3",
  years = 2001:2020,
  max_run = 0
)

fut_proj <- input_gcms(dbCon,
  bbox = the_bb,
  gcms = "EC-Earth3",
  ssps = "ssp245",
  period = "2021_2040",
  max_run = 0
)

fut_proj_ts <- input_gcm_ssp(dbCon,
  bbox = the_bb,
  gcms = "EC-Earth3",
  ssps = "ssp245",
  years = 2021:2040,
  max_run = 0
)

hist_obs <- input_obs(dbCon,
  bbox = the_bb,
  period = "2001_2020"
)
hist_obs_ts <- input_obs_ts(dbCon,
  bbox = the_bb,
  years = 2001:2020
)
```

```{r, echo = FALSE, fig.show = 'hold', fig.cap = "Downloaded historical and future anomalies shown with North Vancouver area and the requested bounding box.", fig.dim = c(12, 5), out.width = "100%"}
minmax <- range(
  minmax(hist_obs_ts[["cru.gpcc"]][["cru.gpcc_Tmax_07_2001"]]),
  minmax(hist_obs[[1]][["Tmax_07"]]),
  minmax(hist_proj[[1]][["EC-Earth3_Tmax_07_ensembleMean_2001"]]),
  minmax(fut_proj[[1]][["EC-Earth3_Tmax_07_ssp245_ensembleMean_2021_2040"]])
)

par(mfrow = c(1, 4))
plot(hist_obs_ts[[1]][["cru.gpcc_Tmax_07_2001"]],
  col = hcl.colors(50, "Reds", rev = 1), type = "continuous",
  mar = c(2, 2, 1, 4), range = minmax,
  main = "Max temp. July\nobserved anomaly 2001",
  fun = function() {
    polys(vancouver_poly)
    polys(plotVect, lty = 2)
  }
)
plot(hist_obs[[1]][["Tmax_07"]],
  col = hcl.colors(50, "Reds", rev = 1), type = "continuous",
  mar = c(1, 2, 1, 4), range = minmax,
  main = "Max temp. July\nobserved anomaly 2001-2020",
  fun = function() {
    polys(vancouver_poly)
    polys(plotVect, lty = 2)
  }
)
plot(hist_proj[[1]][["EC-Earth3_Tmax_07_ensembleMean_2001"]],
  col = hcl.colors(50, "Reds", rev = 1), type = "continuous",
  main = "Max temp. July\n projected historical anomaly, 2001",
  mar = c(1, 2, 1, 4), range = minmax,
  fun = function() {
    polys(vancouver_poly)
    polys(plotVect, lty = 2)
  }
)
plot(fut_proj[[1]][["EC-Earth3_Tmax_07_ssp245_ensembleMean_2021_2040"]],
  col = hcl.colors(50, "Reds", rev = 1), type = "continuous",
  mar = c(1, 2, 1, 4), range = minmax,
  main = "Max temp. July\n projected future anomaly, 2021-2040",
  fun = function() {
    polys(vancouver_poly)
    polys(plotVect, lty = 2)
  }
)
par(mfrow = c(1, 1))
```

### 3) Downscale and calculate actual values (i.e., not anomalies)

Now that we have all necessary inputs, we can downscale the climate
data. To avoid repeating the same lines of code for each input, we'll
use `lapply()` and `do.call()` to iterate over the several climate inputs to
downscale.

Note that for `do.call()` to work, our list of climate inputs (`inputs`) must be
named according to `downscale()`'s argument names (you can list them with
`formalArgs(downscale)`).

```{r, results = "hide"}


all_downscale <- downscale_core(xyzDT, refmap = normals, gcms = fut_proj, obs = hist_obs, gcm_ssp_ts = fut_proj_ts, gcm_hist_ts = hist_proj, obs_ts = hist_obs_ts, vars = "MAT", out_spatial = FALSE)
all_downscale
```

```{r, echo = FALSE}
options(datatable.print.nrows = 10)

all_downscale
```


```{r, echo = FALSE}
knitr::kable(all_downscale[id == head(id, 1)], caption = "'all_downscale' table after binding. Outputs are shown for one location ('id')")
```

## References
